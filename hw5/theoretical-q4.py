"""
Alon Weissfeld   307941310
Matan Hazan      203529136
"""

import numpy as np
import time
import datetime
import itertools

def main(vectors_amount=20000, dimension=20):
    """
    Answers the criteria for HW5 (Theoretical part) question 4 to
    demonstrate the usefulness of using kernels.
    """
    # 4.a. Draw random vectors.
    vectors = np.random.randn(vectors_amount, dimension)

    # 4.b. Calculate a Gram matrix, i.e., each cell i,j in the matrix is the
    # result of applying the kernel function on the vectors i and j.
    # Also, measure the time for this process.
    start = time.time()
    gram_matrix = kernel_matrix(vectors)

    # We're done calculating matrix.
    kernel_time = time.time() - start

    # 4.d. Use Phi to map the vectors to the higher dimension. See the
    # 'phi' method for details. Also, start measuring the time to
    # analyze the Phi mapping process duration.
    start = time.time()
    phi_vectors = np.array([phi(vector) for vector in vectors])

    # 4.e. Calculate the matrix where each cell i,j is the result
    # of the dot product of the mapping images of the vectors i and j.
    phi_matrix = np.matmul(phi_vectors, phi_vectors.T)

    # We're done calculating matrix.
    phi_time = time.time() - start

    # 4.f. Compare the two different methods - phi mapping vs. kernels.
    # Both should be the same size.
    assert(np.allclose(gram_matrix, phi_matrix))
    print('Matrices are close.')

    # 4.g. Compare the time it took the machine to calculate the two matrices.
    kernel_dt = str(datetime.timedelta(seconds=kernel_time))
    phi_dt = str(datetime.timedelta(seconds=phi_time))
    print('Matrix generation by Kernel: ' + kernel_dt)
    print('Matrix generation by Phi Mapping: ' + phi_dt)

    if kernel_time < phi_time:
        percent = (kernel_time / phi_time) * 100
        print('Matrix generated by kernel took ' + \
            '{0:.2f}% of the time to generate Phi matrix.'.format(percent))

    # We observe that the Gram Matrix, which was processed by the Kernel,
    # was much faster to calculate than the matrix which was processed
    # by the Phi Mapping in higher dimensions. This corresponds to what
    # we saw in class and fits the principle of the Kernel "trick".

def kernel_matrix(vectors):
    """
    Generates a Gram Matrix for the given vectors set, by the following
    kernel function: K(x,y) = (x * y + 1) ^ 2
    """
    return (np.matmul(vectors, vectors.T) + 1) ** 2

def phi(x):
    """
    4.c. Defines the associated phi mapping function, which is similiar to
    the phi function presented at recitaion 7 - kernel trick example #2.
    The dimension in which we map to is 231.
    """
    sqaure2_values = map(lambda val: val * np.sqrt(2), x)
    power_values = map(lambda val: val * val, x)

    combs = list(itertools.combinations(x, 2))
    tuples_values = map(lambda (a, b): a * b * np.sqrt(2), combs)

    return np.concatenate(([1], sqaure2_values, power_values, tuples_values))

if __name__ == '__main__':
    main()
